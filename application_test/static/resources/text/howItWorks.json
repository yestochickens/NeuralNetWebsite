{
    "p1": "Neural networks are a type of computational model made to recognize patterns. It does so by learning through massive sample sizes of data that can help it make correct predictions/decisions. Neural networks were developed to function similarly to how a human brain works.",
    "p2": "The human brain consists of billions of neurons: cells responsible for transmitting/communicating information through your nervous system. They are interconnected, allowing for instant reception of signals between any part of your body.",
    "p3": "Neural networks have neurons too; however, they are called nodes. They serve the same function as neurons, working to communicate and allow for the flow of information. All forms of neural networks, no matter how complex, use nodes.",
    "p4": "A simple model, like our own, is a feedforward neural network, where data only moves in one direction, forward. This neural network works by sending data through three layers composed of nodes.",
    "p5": "The first layer is the input layer, which takes incoming data to be processed. Each node will correspond to some value from the data and hold information to be communicated and recognized. In our neural network, we have 784 input nodes (a 28 by 28 grid of data that provides us with 28^2 values of data).",
    "p6": "The next layer is called the hidden layer. This is the layer responsible for performing the computations and transformations to the data so that patterns can be recognized. In our neural network, we have two hidden layers.",
    "p7": "To understand how data flows through these layers we must first understand the concepts of weights and biases.",
    "p8": "In each layer, all of the nodes have a connection to all other nodes in the previous layer. These connections are known as weights, and they are adjustable parameters that can change how much one node’s output affects another node’s input. This is calculated in a weighted sum of all the inputs from the previous layer.",
    "p9": "Along with weights, each node also has a bias, a value that is added that allows for greater flexibility in output.",
    "p10": "After calculations are performed by multiplying the weight and adding the bias, the resulting value is passed through an activation function. These are important as they allow for non-linearity and the creation of pattern recognition. With linear functions, we wouldn’t be able to handle large amounts of data. Some examples of activation functions are ReLu, sigmoid, and tanh (all can seen above).",
    "p11": "After the data is passed through the two hidden layers it is multiplied by a final weight, a bias is added and then it is passed through another activation function. The data now finally settles into the output layer, where values are assigned to new nodes that give us a result. In our neural network case, the values are interpreted as probabilities, indicating the network’s confidence in its predictions. The highest probability indicates the digit the neural network believes is drawn."
}